{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e7386-bb64-4bcf-9a1d-184d8ee128f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "team_member_id = \"M2\"\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2023-01-01&endtime=2023-01-02\"\n",
    "\n",
    "data_lines = import_data(url)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24cf1f-1f1b-4bf2-b2fa-8d9f914963ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data_text = response.text\n",
    "    else:\n",
    "        raise Exception(\"Failed to download data.\")\n",
    "    \n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "\n",
    "    file_path = os.path.join(\"data\", f\"dataset_{team_member_id}.txt\")\n",
    "\n",
    "    with open(file_path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(data_text)\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        data_lines = f.readlines()\n",
    "    return data_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84751ee-e19c-47cf-a343-28e97900a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This was the import data function from m2.\n",
    "#I realised that most people followed the code examples provided so they open the file twice. Once for writing and\n",
    "#once for reading. However I learned that you dont have to open the file twice and instead combine the two.\n",
    "#Otherwise the code is good and works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de37f5-ddbb-4522-8d09-0d79678a8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data_text_list):\n",
    "    data_str = \"\".join(data_text_list)\n",
    "    csv_reader = csv.reader(StringIO(data_str))\n",
    "    header = next(csv_reader)\n",
    "\n",
    "    date_index = header.index(\"time\")\n",
    "\n",
    "    cleaned_rows = [header]\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            original_date = row[date_index]\n",
    "            original_date = original_date.rstrip(\"Z\")\n",
    "            dt = datetime.fromisoformat(original_date)\n",
    "            formatted_date = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            row[date_index] = formatted_date\n",
    "        except Exception as e:\n",
    "            print(f\"Error proccessing row: {e}\")\n",
    "        cleaned_rows.append(row)\n",
    "\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "\n",
    "    output_file = os.path.join(\"output\", f\"cleaned_data_{team_member_id}.txt\")\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(cleaned_rows)\n",
    "\n",
    "    cleaned_text_lines = [\",\".join(row) + \"\\n\" for row in cleaned_rows]\n",
    "    return cleaned_text_lines\n",
    "clean_data(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e76d7f-20b2-4007-a3d5-bd42f97df8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code works as intended. maybe some comments would help to make it easier to understand\n",
    "#and improve.There also seems to be an with the date being y m d instead of dmy which can be\n",
    "#fixed easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167d62c-d41d-4f20-a18f-27bc5acf67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "team_member_id = \"M2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c1d84-cffb-45b6-a7ee-f96786a0440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data_text = response.text\n",
    "    else:\n",
    "        raise Exception(\"Failed to download data.\")\n",
    "    \n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "\n",
    "    file_path = os.path.join(\"data\", f\"dataset_{team_member_id}.txt\")\n",
    "\n",
    "    with open(file_path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(data_text)\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        data_lines = f.readlines()\n",
    "    return data_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3c187-61d7-4d77-aebe-f1263c9c6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works as intended. same thing with m2 with the file opening twice.\n",
    "#code is efficient and handles error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5038cd-45df-4b14-b12a-2bd39fda44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = import_data(url)\n",
    "\n",
    "\n",
    "def clean_data(data_list):\n",
    "    data_string = ''.join(data_list)\n",
    "    csv_reader = csv.reader(StringIO(data_string))\n",
    "    \n",
    "    header_row = next(csv_reader)\n",
    "    date_index = header_row.index('time')\n",
    "    cleaned_rows = [header_row]\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            og_date = row[date_index].rstrip('Z')\n",
    "            dt = datetime.fromisoformat(og_date)\n",
    "            row[date_index] = dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "        except Exception as e:\n",
    "            print(f'There was an error processing row {e}')\n",
    "        cleaned_rows.append(row)\n",
    "        \n",
    "        \n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    output_file = os.path.join('output', 'cleaned_data_M3.txt')\n",
    "    \n",
    "    with open(output_file, 'w', newline= '', encoding= 'utf-8') as f:\n",
    "        csv.writer(f).writerows(cleaned_rows)\n",
    "    \n",
    "    cleaned_text= [','.join(row) + '\\n' for row in cleaned_rows]\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "#clean_data(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886fbdf-bd25-45d3-84a0-bd6a9a160364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the overall strucute of the code is very similar to m2. the date is returned in  the correct\n",
    "#format. errors and handled well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f50dd-7028-402c-9fe2-313a7265dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall feedback for both would be to try to include comments to make it easier\n",
    "#to understand now and later when revision is needed. Both scripts handles error and works as \n",
    "#intended which is good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
