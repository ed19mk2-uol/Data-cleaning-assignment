{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports needed to run scripts\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2023-01-01&endtime=2023-12-31&minmagnitude=5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Review for M1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing M1 import function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport sys\\nprint(sys.stdout.encoding) #checking the encoding as the encoding was not specified in the function, returning an error as the system's defualt encoding was charmap\\n\\nimport_data(url) #testing the import data function runs once encoding was specified (yes)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_data(url):\n",
    "    os.makedirs('data', exist_ok=True)#creates the data folder if it already exists ignore\n",
    "    file_name = 'dataset_M1.txt'#file name\n",
    "    file_path = os.path.join('data', file_name)#path for the file\n",
    "    response = requests.get(url)#get the url\n",
    "    if response.status_code == 200:  #if the url request was sucessful\n",
    "        with open(file_path, 'w', encoding= 'utf-8') as file:  # Open the file in write mode \n",
    "            file.write(response.text)  # Write the content to the file\n",
    "\n",
    "        with open(file_path, 'r', encoding= 'utf-8') as file:  # Open the file in read mode\n",
    "            lines = file.readlines()  # Read all lines into a list\n",
    "        return lines#returns them\n",
    "\n",
    "#checks:\n",
    "'''\n",
    "import sys\n",
    "print(sys.stdout.encoding) #checking the encoding as the encoding was not specified in the function, returning an error as the system's defualt encoding was charmap\n",
    "\n",
    "import_data(url) #testing the import data function runs once encoding was specified (yes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing M1 cleaning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif data_lines:\\n    clean_data(data_lines)#output\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def clean_data(data_lines):\n",
    "    os.makedirs('output', exist_ok=True)#creates output folder if it already exists ignore\n",
    "    cleaned_file_name = 'cleaned_data_M1.txt'#file name\n",
    "    cleaned_file_path = os.path.join('output', cleaned_file_name)#path for the file\n",
    "    with open(cleaned_file_path, 'w') as cleaned_file:#opens file in write mode\n",
    "        for line in data_lines[1:]:#for ignoring headers\n",
    "            columns = line.strip().split(',')#removes any whitespace and seperates it into columns\n",
    "            timestamp = columns[0]#first coloumn\n",
    "\n",
    "            try:#this is to skip any errors\n",
    "                dt = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")#matches the current time format\n",
    "                formatted_time = dt.strftime(\"%Y-%m-%d %H:%M:%S\")#converts it in to the format we need\n",
    "                print(f\"Original: {timestamp} -> Formatted: {formatted_time}\")#fancy way of printing old and new\n",
    "\n",
    "                cleaned_file.write(formatted_time + '\\n')#writes the formatted time with a new line\n",
    "            except ValueError:\n",
    "                print(f\"Skipping invalid timestamp: {timestamp}\")#this skips any invalid lines\n",
    "                continue#continues the loop\n",
    "\n",
    "\n",
    "\n",
    "data_lines = import_data(url)#input\n",
    "'''\n",
    "if data_lines:\n",
    "    clean_data(data_lines)#output\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1's functions both effectively import and clean the data. However, M1's import code orginally produced an error when trying to run it. This is because the encoding (utf-8) was not specified and the defualt encoding being used was charmap, producing a UnicodeEncodeError. I resolved this error by specifying the encoding to be utf-8 in the open file functions which is something M1 could add to their code to prevent this error.   \n",
    "The comments M1 included on each line meant the code was very clear throughout, making it easier to read and understand each code line's purpose in the functions.   \n",
    "The code overall was very efficient. To improve efficiency even further, some aspects of the code could be condensed, for example in the import function, one open file function could be used instead of two by changing the mode used to be w+ (instead of r and w individually, w+ reads and writes the file).\n",
    "If using the w+ mode instead, ensure to reset the file pointer back to the start of the file using the line f.seek(0).   \n",
    "Also, M1 appears to have cleaned the data in the reverse format specified in the assignment brief. M1's data is in the format YYYY-MM-DD instead of DD-MM-YYYY. This can easily be resolved by editing the order of Y,m,d in the formatted_date definition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Review for M2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing M2 import function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport_data(url)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "team_member_id = \"M2\"\n",
    "\n",
    "# New function to import data\n",
    "\n",
    "def import_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data_text = response.text\n",
    "    else:\n",
    "        raise Exception(\"Failed to download data.\")\n",
    "    \n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "\n",
    "    file_path = os.path.join(\"data\", f\"dataset_{team_member_id}.txt\")\n",
    "\n",
    "    with open(file_path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(data_text)\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as f:\n",
    "        data_lines = f.readlines()\n",
    "    return data_lines\n",
    "\n",
    "# Running the following code will import the data\n",
    "'''\n",
    "import_data(url)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing M2 cleaning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclean_data(data_lines)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_lines = import_data(url)\n",
    "\n",
    "# New function to clean data\n",
    "\n",
    "def clean_data(data_text_list):\n",
    "    data_str = \"\".join(data_text_list)\n",
    "    csv_reader = csv.reader(StringIO(data_str))\n",
    "    header = next(csv_reader)\n",
    "\n",
    "    date_index = header.index(\"time\")\n",
    "\n",
    "    cleaned_rows = [header]\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            original_date = row[date_index]\n",
    "            original_date = original_date.rstrip(\"Z\")\n",
    "            dt = datetime.fromisoformat(original_date)\n",
    "            formatted_date = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            row[date_index] = formatted_date\n",
    "        except Exception as e:\n",
    "            print(f\"Error proccessing row: {e}\")\n",
    "        cleaned_rows.append(row)\n",
    "\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "\n",
    "    output_file = os.path.join(\"output\", f\"cleaned_data_{team_member_id}.txt\")\n",
    "\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(cleaned_rows)\n",
    "\n",
    "    cleaned_text_lines = [\",\".join(row) + \"\\n\" for row in cleaned_rows]\n",
    "    return cleaned_text_lines\n",
    "\n",
    "# Running the following code will clean the data\n",
    "'''\n",
    "clean_data(data_lines)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2's functions both effectively import and clean the data however, like in M1's cleaning funcction, M2 also formats the cleaned data in the reverse order as specified in the assignment brief. M2's clean data is of the format YYYY-MM-DD rather than DD-MM-YYYY. \n",
    "M2's use of whitespace makes their code clearer and easier to read. To improve clarity further, they could include mroe comments throughout their code. \n",
    "To improve efficiency and reduce unnecessary complexity, M2 could also remove the need for the variable of team_member_id and just use their id 'M2' in the strings when required.  \n",
    "M2 could also eradicate the need for the if not statements (regarding mkaing the directory) by just including the parameter exists_ok=True in the os.makedirs() function.  \n",
    "The import function could also use one open file function instead of two by changing the mode used to be w+ (instead of r and w individually, w+ reads and writes the file).  \n",
    "If using the w+ mode instead, M2 should ensure to reset the file pointer back to the start of the file using the line f.seek(0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
